{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lisaadnr/normalization-ayat/blob/main/Normalisasi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PlXHEKQ_n9b",
        "outputId": "8c69cb0b-178b-4717-fd8e-acd9e2c1c33f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "import os\n",
        "import re\n",
        "\n",
        "def extract_ayat_text(doc_path):\n",
        "    doc = Document(doc_path)\n",
        "    ayat_texts = []\n",
        "\n",
        "    # Kata-kata yang harus dihapus jika muncul di awal kalimat (huruf kapital)\n",
        "    ignored_keywords = [\n",
        "        \"AL\", \"AS\", \"AT\", \"YAS\", \"Madaniyyah\", \"Makkiyyah\", \"AN\", \"'ABASA\",\n",
        "        \"NUH\", \"QAF\", \"AS\", \"AD\", \"ASY\", \"FUSSILAT\", \"SAD\", \"GAFIR\", \"AZ\",\n",
        "        \"MUHAMMAD\", \"ALI\", \"MARYAM\", \"TAHA\", \"AR\", \"QURAISY\", \"IBRAHIM\",\n",
        "        \"YASIN\", \"YUNUS\", \"HUD\", \"YUSUF\", \"FATIR\", \"SABA\", \"LUQMAN\"\n",
        "    ]\n",
        "\n",
        "    ignored_phrase = \"Dengan nama Allah Yang Maha Pengasih lagi Maha Penyayang\"\n",
        "\n",
        "    # Periksa apakah ini Surah Al-Fatihah berdasarkan nama file\n",
        "    is_alfatihah = \"alfatihah\" in os.path.basename(doc_path).lower()\n",
        "\n",
        "    for para in doc.paragraphs:\n",
        "        text = para.text.strip()\n",
        "\n",
        "        # Skip paragraf kosong\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        # Skip teks dengan kata di awal yang termasuk dalam ignored_keywords\n",
        "        if re.match(rf\"^({'|'.join(ignored_keywords)})\\b\", text):\n",
        "            continue\n",
        "\n",
        "        # Hapus frasa \"Dengan nama Allah...\" jika bukan Surah Al-Fatihah\n",
        "        if ignored_phrase in text and not is_alfatihah:\n",
        "            continue\n",
        "\n",
        "        # Jika paragraf tidak diawali dengan angka dan teksnya bold, lewati\n",
        "        if not re.match(r'^\\d+\\.', text) and any(run.bold for run in para.runs):\n",
        "            continue\n",
        "\n",
        "        # Skip teks yang diawali dengan \"Surah\"\n",
        "        if text.startswith(\"Surah\"):\n",
        "            continue\n",
        "\n",
        "        # Hapus tanda kurung kapital (termasuk Unicode) di awal paragraf\n",
        "        text = re.sub(r'^\\([A-ZĀĒĪŌŪṢḌṬẒʿ\\s\\-]+\\)', '', text).strip()\n",
        "\n",
        "        # Skip seluruh kalimat jika mengandung kata dalam kurung huruf kapital\n",
        "        if re.search(r'\\([A-Z\\s]+\\)', text):\n",
        "            continue\n",
        "\n",
        "        # Hapus catatan kaki (misalnya 1), 2), dst.)\n",
        "        text = re.sub(r'\\d+\\)', '', text)\n",
        "\n",
        "        # Hapus tanda kurung tutup di akhir kalimat\n",
        "        text = re.sub(r'\\s*\\)\\s*$', '', text)  # Hapus jika `)` di akhir kalimat\n",
        "        text = re.sub(r'\\s*\\)\\b', '', text)  # Hapus jika `)` di akhir kata\n",
        "\n",
        "        # Tambahkan teks yang telah dibersihkan ke list ayat_texts\n",
        "        ayat_texts.append(text.strip())\n",
        "\n",
        "    # Gabungkan semua ayat menjadi satu teks dan hilangkan spasi/enter di awal dan akhir\n",
        "    return \"\\n\".join(ayat_texts).strip()\n",
        "\n",
        "# Path ke folder yang berisi file DOCX\n",
        "folder_path = '/content/sample_data/ayat'\n",
        "\n",
        "# Folder output untuk menyimpan file hasil normalisasi\n",
        "output_folder = '/content/sample_data/mpat'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Loop melalui setiap file DOCX di folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.docx'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        ayat_text = extract_ayat_text(file_path)\n",
        "\n",
        "        # Simpan hasilnya ke file TXT di folder output\n",
        "        output_file_path = os.path.join(output_folder, f\"{filename.replace('.docx', '')}_normalized.txt\")\n",
        "        with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(ayat_text)\n",
        "        print(f\"Processed: {filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sNmgD0bwQVa",
        "outputId": "7f2b3e9a-0048-4783-fa84-806f63f315f4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: 111. al-Lahab.docx\n",
            "Processed: 34. Saba'.docx\n",
            "Processed: 82. al-Infitar.docx\n",
            "Processed: 27. an-Naml.docx\n",
            "Processed: 49. al-Hujurat.docx\n",
            "Processed: 90. al-Balad.docx\n",
            "Processed: 96. al-'Alaq.docx\n",
            "Processed: 83. al-Mutaffifin.docx\n",
            "Processed: 17. al-Isra'.docx\n",
            "Processed: 59. al-Hasyr.docx\n",
            "Processed: 53. an-Najm.docx\n",
            "Processed: 32. as-Sajdah.docx\n",
            "Processed: 3. Ali 'Imran.docx\n",
            "Processed: 30. ar-Rum.docx\n",
            "Processed: 109. al-Kafirun.docx\n",
            "Processed: 55. ar-Rahman.docx\n",
            "Processed: 63. al-Munafiqun.docx\n",
            "Processed: 76. al-Insan.docx\n",
            "Processed: 23. al-Mu'minun.docx\n",
            "Processed: 4. an-Nisa'.docx\n",
            "Processed: 100. al-'Adiyat.docx\n",
            "Processed: 113. al-Falaq.docx\n",
            "Processed: 25. al-Furqan.docx\n",
            "Processed: 39. az-Zumar.docx\n",
            "Processed: 60. al-Mumtahanah.docx\n",
            "Processed: 20. Taha.docx\n",
            "Processed: 86. at-Tariq.docx\n",
            "Processed: 8. al-Anfal.docx\n",
            "Processed: 58. al-Mujadalah.docx\n",
            "Processed: 73. al-Muzzammil.docx\n",
            "Processed: 46. al-Ahqaf.docx\n",
            "Processed: 101. al-Qari'ah.docx\n",
            "Processed: 18. al-Kahf.docx\n",
            "Processed: 38. Sad.docx\n",
            "Processed: 43. az-Zukhruf.docx\n",
            "Processed: 29. al-'Ankabut.docx\n",
            "Processed: 24. an-Nur.docx\n",
            "Processed: 52. at-Tur.docx\n",
            "Processed: 84. al-Insyiqaq.docx\n",
            "Processed: 62. al-Jumu'ah.docx\n",
            "Processed: 108. al-Kausar.docx\n",
            "Processed: 61. as-Saff.docx\n",
            "Processed: 50. Qaf.docx\n",
            "Processed: 41. Fussilat.docx\n",
            "Processed: 35. Fatir.docx\n",
            "Processed: 93. ad-Duha.docx\n",
            "Processed: 45. al-Jasiyah.docx\n",
            "Processed: 19. Maryam.docx\n",
            "Processed: 69. al-Haqqah.docx\n",
            "Processed: 99. az-Zalzalah.docx\n",
            "Processed: 6. al-An'am.docx\n",
            "Processed: 47. Muhammad.docx\n",
            "Processed: 98. al-Bayyinah.docx\n",
            "Processed: 48. al-Fath.docx\n",
            "Processed: 112. al-Ikhlas.docx\n",
            "Processed: 9. at-Taubah.docx\n",
            "Processed: 92. al-Lail.docx\n",
            "Processed: 88. al-Gasyiyah.docx\n",
            "Processed: 103. al-'Asr.docx\n",
            "Processed: 5. al-Ma'idah.docx\n",
            "Processed: 31. Luqman.docx\n",
            "Processed: 22. al-Hajj.docx\n",
            "Processed: 65. at-Talaq.docx\n",
            "Processed: 91. asy-Syams.docx\n",
            "Processed: 105. al-Fil.docx\n",
            "Processed: 75. al-Qiyamah.docx\n",
            "Processed: 56. al-Waqi'ah.docx\n",
            "Processed: 26. asy-Syu'ara'.docx\n",
            "Processed: 74. al-Muddassir.docx\n",
            "Processed: 66. at-Tahrim.docx\n",
            "Processed: 80. 'Abasa.docx\n",
            "Processed: 77. al-Mursalat.docx\n",
            "Processed: 42. asy-Syura.docx\n",
            "Processed: 110. an-Nasr.docx\n",
            "Processed: 37. as-Saffat.docx\n",
            "Processed: 104. al-Humazah.docx\n",
            "Processed: 11. Hud.docx\n",
            "Processed: 16. an-Nahl.docx\n",
            "Processed: 51. az-Zariyat.docx\n",
            "Processed: 97. al-Qadr.docx\n",
            "Processed: 72. al-Jinn.docx\n",
            "Processed: 2. al-Baqarah.docx\n",
            "Processed: 70. al-Ma'arij.docx\n",
            "Processed: 15. al-Hijr.docx\n",
            "Processed: 67. al-Mulk.docx\n",
            "Processed: 64. at-Tagabun.docx\n",
            "Processed: 78. an-Naba'.docx\n",
            "Processed: 87. al-A'la.docx\n",
            "Processed: 54. al-Qamar.docx\n",
            "Processed: 102. at-Takasur.docx\n",
            "Processed: 95. at-Tin.docx\n",
            "Processed: 106. Quraisy.docx\n",
            "Processed: 89. al-Fajr.docx\n",
            "Processed: 79. an-Nazi'at.docx\n",
            "Processed: 12. Yusuf.docx\n",
            "Processed: 7. al-A'raf.docx\n",
            "Processed: 57. al-Hadid.docx\n",
            "Processed: 14. Ibrahim.docx\n",
            "Processed: 85. al-Buruj.docx\n",
            "Processed: 36. Yasin.docx\n",
            "Processed: 21. al-Anbiya'.docx\n",
            "Processed: 81. at-Takwir.docx\n",
            "Processed: 107. al-Ma'un.docx\n",
            "Processed: 10. Yunus.docx\n",
            "Processed: 114. an-Nas.docx\n",
            "Processed: 28. al-Qasas.docx\n",
            "Processed: 13. ar-Ra'd.docx\n",
            "Processed: 44. ad-Dukhan.docx\n",
            "Processed: alfatihah.docx\n",
            "Processed: 71. Nuh.docx\n",
            "Processed: 40. Gafir.docx\n",
            "Processed: 33. al-Ahzab.docx\n",
            "Processed: 94. asy-Syarh.docx\n",
            "Processed: 68. al-Qalam.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "# Path ke folder output\n",
        "output_folder = '/content/sample_data/mpat'\n",
        "\n",
        "# Nama file ZIP yang akan dibuat\n",
        "zip_file_path = '/content/kesepuluh.zip'\n",
        "\n",
        "# Kompres folder ke dalam ZIP\n",
        "with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
        "    for root, dirs, files_in_dir in os.walk(output_folder):\n",
        "        for file in files_in_dir:\n",
        "            # Tambahkan file ke dalam ZIP dengan struktur folder\n",
        "            zipf.write(os.path.join(root, file),\n",
        "                       arcname=os.path.relpath(os.path.join(root, file), output_folder))\n",
        "\n",
        "# Download file ZIP\n",
        "files.download(zip_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hto2A3uTZ9lc",
        "outputId": "f3e28538-e988-4f86-8305-4a133347f75a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3aff95f5-2664-4bdb-a7ed-9f6f1598deae\", \"kesepuluh.zip\", 1129506)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}